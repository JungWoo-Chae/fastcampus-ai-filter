{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf38cbf-c8be-4a08-b541-65925f293b21",
   "metadata": {},
   "source": [
    "# DDPM (Denoising Diffusion probabilistic Model)\n",
    "\n",
    "https://arxiv.org/abs/2006.11239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af1213-0085-47b5-b620-3d9bf9e1b8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13128e-74a0-4b8c-a551-0a2798a8fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ab039d-b402-42ed-b442-9bfd76d67777",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0579085-6322-4722-9922-d6b3d38a5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa215e5-077b-4d3d-9527-947e85f7e428",
   "metadata": {},
   "source": [
    "## Forward Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b5f9c-7474-4ac7-9a9c-02a612ebdf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_process(x_0, t, beta):\n",
    "    \"\"\"\n",
    "    Simulate the forward process of the diffusion model.\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_0)\n",
    "    alpha = 1 - beta\n",
    "    alpha_cumprod = alpha.cumprod(dim=0)\n",
    "    x_t = (alpha_cumprod[t]**0.5) * x_0 + (1 - alpha_cumprod[t])**0.5 * noise\n",
    "    return x_t, noise\n",
    "\n",
    "T = 1000  # Total time steps\n",
    "beta = torch.linspace(1e-4, 0.02, T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a42be4-ec10-4941-9a82-f90e3e825b1b",
   "metadata": {},
   "source": [
    "## Reverse Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44288b54-2cc9-481b-a4f1-0cf47523911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 1, 3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = UNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25d932-75c7-4041-ad97-3f94819423b9",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bb4b7-0e12-4995-8508-9dd8e98152f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(pred, target):\n",
    "    return ((pred - target)**2).mean()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, _ in dataloader:\n",
    "        t = torch.randint(0, T, (x_batch.size(0),), device=x_batch.device).long()\n",
    "        x_batch = x_batch.to(torch.float32).to(model.device)\n",
    "        x_t, noise = forward_process(x_batch, t, beta)\n",
    "        optimizer.zero_grad()\n",
    "        noise_pred = model(x_t)\n",
    "        loss = loss_fn(noise_pred, noise)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
